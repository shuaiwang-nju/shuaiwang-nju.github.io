---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- {% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %} -->

<span class='anchor' id='about-me'></span>


Dr. Shuai Wang is currently a Tenure-Track Associate Professor at the School of Intelligence Science and Technology, Nanjing University. He earned his B.E. degree from Northwestern Polytechnical University in 2014 under the supervision of [Prof. Lei Xie](http://lxie.npu-aslp.org/), and his Ph.D. degree from Shanghai Jiao Tong University in 2020 under the supervision of [Prof. Kai Yu](https://x-lance.github.io/kaiyu/) and [Prof. Yanmin Qian](https://audiocc.sjtu.edu.cn/en/members/yanmin.qian). Prior to joining Nanjing University, he served as a research scientist in [Prof. Haizhou Li](https://www.colips.org/~eleliha/)'s team at the Shenzhen Research Institute of Big Data, Chinese University of Hong Kong (Shenzhen), where he still holds an adjunct position now. Additionally, he spent 2.5 years as a senior research scientist at Lightspeed & Quantum Studios, Tencent, where he led the speech group in R&D of speech technologies customized for games.

His research interest includes speaker modeling,target speaker processing,  speech synthesis, voice conversion and music generation. He has published more than 60 papers at top-tier speech conferences/journals. 

<!-- <a href='https://scholar.google.com/citations?user=vW1ZaucAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a> -->


# 🔥 Openings
I will have several openings for graduate students (2026 Fall), will update details ASAP. I am currently looking for research assistants, please feel free to drop me an email with your CV if you are interested in the following topics:

- Speaker Modeling
- Target Speaker Processing
- Speech Generation
- Music Generation
- Brain-inspired speech processing

> Note that research assistants can choose to work either in Nanjing University @ Suzhou or in Chinese University of Hong Kong (Shenzhen), jointly supervised with Prof. [Haizhou Li](https://www.colips.org/~eleliha/).

---

<span class='anchor' id='-recruitment'></span>

## 🎓 **招生信息 / Recruitment Information**



<!-- Video Section -->
<div class="video-container" style="text-align: center; margin: 20px 0;">
  <p style="font-size: 14px; color: #666; margin-bottom: 10px; font-style: italic;">
    🎵 基于我们论文 <a href="https://arxiv.org/abs/2506.07634" target="_blank" style="color: #007acc; text-decoration: none;">SongBloom</a> 生成的招生欢迎演示 / Welcome demo generated using our <a href="https://arxiv.org/abs/2506.07634" target="_blank" style="color: #007acc; text-decoration: none;">SongBloom</a> paper
  </p>
  <video width="50%" max-width="500px" controls style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <source src="{{ site.baseurl }}/images/zhike_song.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
</div>

<div class="recruitment-section">

<h3 class="recruitment-title">🔥 2026年秋季研究生招生 / 2026 Fall Graduate Student Recruitment</h3>

<p class="recruitment-subtitle">招生方向 / Research Areas:</p>
<ul class="recruitment-list">
<li><strong>说话人建模 / Speaker Modeling</strong></li>
<li><strong>目标说话人处理 / Target Speaker Processing</strong></li>
<li><strong>语音生成 / Speech Generation</strong></li>
<li><strong>音乐生成 / Music Generation</strong></li>
<li><strong>类脑语音处理 / Brain-inspired Speech Processing</strong></li>
</ul>

<p class="recruitment-subtitle">申请要求 / Requirements:</p>
<ul class="recruitment-list">
<li>计算机科学、电子工程或相关专业背景 / Background in Computer Science, Electronic Engineering, or related fields</li>
<li>对语音处理、机器学习有浓厚兴趣 / Strong interest in speech processing and machine learning</li>
<li>良好的编程能力（Python/C++） / Good programming skills (Python/C++)</li>
<li>英语读写能力良好 / Good English reading and writing skills</li>
</ul>

<p class="recruitment-subtitle">联系方式 / Contact:</p>
<ul class="recruitment-list">
<li>邮箱 / Email: <span id="email-display" class="recruitment-email" style="cursor: pointer;" onclick="showEmail()">点击显示邮箱 / Click to show email</span></li>
<li>请附上简历、成绩单和研究兴趣陈述 / Please include CV, transcripts, and research interest statement</li>
</ul>

<p class="recruitment-subtitle"><strong>南大智科学生特别说明 / Special Notice for NJU Students:</strong></p>
<ul class="recruitment-list">
<li>欢迎大二大三学生进组实习 / Welcome sophomore and junior students for internships</li>
<li class="office-highlight">南大智科学生可到南雍楼西536办公室面聊 / NJU students can drop by Room 536 at Nanyong Building for face-to-face discussion</li>
<li>实习期间可参与实际科研项目 / Interns can participate in actual research projects</li>
</ul>

</div>

# 👨‍🎓 Students

Ph.D. students jointly supervised with Prof. [Haizhou Li](https://www.colips.org/~eleliha/)

- Chenyu Yang, CUHK-Shenzhen, Music Generation, Intern at Tencent AILab （犀牛鸟人才计划）.
- [Zhijun Liu](https://zjlww.github.io/), CUHK-Shenzhen, Speech Synthesis, Intern at NetEase and Bytedance (TopSeed)
- [Sho Inoue](https://www.linkedin.com/in/sho-inoue-41646a1a2/), CUHK-Shenzhen, Speech Syntesis, Intern at NetEase and Meta FAIR.
- [Qibing Bai](https://p1ping.github.io/), CUHK-Shenzhen, Accent Conversion, Intern at Tencent TEA-Lab
- Wenxuan Wu, CUHK, Target Speech Extraction
- Wupeng Wang, NUS, Speech Separation

## Past students

- [Junjie Li](https://mrjunjieli.github.io/), currently Ph.D. student at The Hong Kong Polytechnic University



# 📝 Publications 

Please check my [Google Scholar](https://scholar.google.com/citations?user=vW1ZaucAAAAJ) for the latest publications.

# 🪜 Open-Source Projects

- [WeSpeaker](https://github.com/wenet-e2e/wespeaker): Speaker Embedding Learning
- [WeSep](https://github.com/wenet-e2e/wesep): Target Speaker Extraction.
- [DiffRhythm](https://github.com/ASLP-lab/DiffRhythm): Diffusion-based Rhythmic Music Generation.


# 🎖 Honors and Awards
- *2024* Best Paper Award, ISCSLP 2024
- *2024* Best Student Paper Award, ISCSLP 2024
- *2019* VoxSRC 2019:	Rank 1st in both 2 Tracks
- *2019* DIHARD 2019: Rank 1st in both 4 Tracks
- *2018* IEEE Ganesh N. Ramaswamy Memorial Student Grant Award

# 🌅 Services
I serve as a regular reviewer for multiple conferences and journals, including 
- ICASSP, Interspeech, ASRU, SLT, T-ASLP, Computer Speech & Language, Speech Communication; 
- ICML, Neurips, AAAI, ACM MM.

I serve as the Specical Session Chair of APSIPA 2025, the Operation Chair of ICASSP 2025 Suzhou Satellite Event, the Publication Chair of SLT 2024.


# 💬 Invited Talks
- *2024.09*, [Speaker Representation Learning: Theories, Applications and Practice](https://vgs-it.fit.vutbr.cz/2024/09/03/shuai-wang-speaker-representation-learning-theories-applications-and-practiceshuai-wang/) at Brno University of Technology. [\[video\]](https://www.youtube.com/live/FMY5_smgrYY)

