---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Dr. Shuai Wang is currently a Tenure-Track Associate Professor at the School of Intelligence Science and Technology, Nanjing University. He earned his B.E. degree from Northwestern Polytechnical University in 2014 and his Ph.D. degree from Shanghai Jiao Tong University in 2020. Prior to joining Nanjing University, he served as a research scientist at the Shenzhen Research Institute of Big Data, Chinese University of Hong Kong (Shenzhen). Additionally, he spent 2.5 years as a senior research scientist at Lightspeed & Quantum Studios, Tencent, where he led the speech group in R&D of speech technologies customized for games.

His research interest includes speaker modeling,target speaker processing,  speech synthesis, voice conversion and music generation. He has published more than 60 papers at top-tier speech conferences/journals. 

<a href='https://scholar.google.com/citations?user=vW1ZaucAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>


# ğŸ”¥ Openings
I will have several openings for graduate students (2026 Fall), will update details ASAP. I am currently looking for research assistants, please feel free to drop me an email with your CV if you are interested in the following topics:

- Speaker Modeling
- Target Speaker Processing
- Speech Generation
- Music Generation
- Brain-inspired speech processing (EEG, sEEG ...)

## ğŸ‘©ğŸ»â€ğŸ“ Students

Ph.D. students jointly supervised with Prof. [Haizhou Li](https://www.colips.org/~eleliha/)

- Chenyu Yang, CUHK-Shenzhen, Music Generation, Intern at Tencent AILab ï¼ˆçŠ€ç‰›é¸Ÿè®¡åˆ’ï¼‰.
- Zhijun Liu, CUHK-Shenzhen, Speech Synthesis, Intern at NetEase and Bytedance (TopSeed)
- Sho Inoue, CUHK-Shenzhen, Speech Syntesis, Intern @ NetEase and Meta FAIR.
- Qibing Bai, CUHK-Shenzhen, Accent Conversion, Intern at Tencent TEA-Lab
- Wenxuan Wu, CUHK, Target Speech Extraction


# ğŸ“ Publications 

Please check my [Google Scholar](https://scholar.google.com/citations?user=vW1ZaucAAAAJ) for the latest publications.

# ğŸ– Open-Source Projects

- [WeSpeaker](https://github.com/wenet-e2e/wespeaker): Speaker Embedding Learning
- [WeSep](https://github.com/wenet-e2e/wesep): Target Speaker Extraction.
- [DiffRhythm](https://github.com/ASLP-lab/DiffRhythm): Diffusion-based Rhythmic Music Generation.


# ğŸ– Honors and Awards
- *2024* Best Paper Award, ISCSLP 2024
- *2024* Best Student Paper Award, ISCSLP 2024
- *2019* VoxSRC 2019:	Rank 1st in both 2 Tracks
- *2019* DIHARD 2019: Rank 1st in both 4 Tracks
- *2018* IEEE Ganesh N. Ramaswamy Memorial Student Grant Award


# ğŸ’¬ Invited Talks
- *2024.09*, [Speaker Representation Learning: Theories, Applications and Practice](https://vgs-it.fit.vutbr.cz/2024/09/03/shuai-wang-speaker-representation-learning-theories-applications-and-practiceshuai-wang/) at Brno University of Technology. [\[video\]](https://www.youtube.com/live/FMY5_smgrYY)

